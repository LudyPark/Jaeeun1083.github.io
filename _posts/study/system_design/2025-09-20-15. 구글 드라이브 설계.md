---
title: System Design. Part15. 구글 드라이브 설계
author: jaeeun
date: 2025-09-20 00:00:00 +0800
categories: [Study, "SystemDesign"]
tags: ["System Design"]
render_with_liquid: false
---

# 15. 구글 드라이브 설계

# 클라우드 저장 시스템의 핵심 기술: 델타 동기화와 강한 일관성

구글 드라이브나 드롭박스를 사용할 때, 1GB 동영상 파일에서 제목만 바꿨는데도 전체 파일이 다시 업로드된다면 어떨까? 여러 사람이 같은 문서를 편집할 때 각자 다른 버전을 본다면? 이런 문제들을 해결하는 것이 현대 클라우드 저장 시스템의 핵심 기술이다.

## 클라우드 저장의 실제 문제들

**주요 문제들:**
- **대역폭 낭비**: 파일 한 글자만 바뀌어도 전체 파일 재전송
- **동기화 지연**: 대용량 파일의 긴 업로드 시간
- **버전 충돌**: 여러 사용자가 동시 편집 시 데이터 불일치
- **저장 공간**: 모든 버전을 저장하면 용량 폭증

이런 문제들을 해결하기 위해 탄생한 것이 델타 동기화와 강한 일관성 기술이다.

---

## Part 1: 델타 동기화 - 변화만 전송하는 방법

### 델타 동기화가 나온 배경

100MB 프레젠테이션 파일에서 오타 하나를 고쳤는데 전체 100MB를 다시 업로드해야 한다면? 필요없는 오버헤드가 발생하게 됨.

#### 기존 파일 동기화의 한계

```kotlin
// 기존 방식의 문제점
fun traditionalSync(file: File) {
    val fileContent = file.readBytes() // 전체 파일 읽기
    uploadToServer(fileContent)       // 전체 파일 업로드
    // 문제: 1바이트 변경에도 전체 파일 전송
}
```

#### 델타 동기화의 등장

이 문제를 해결하기 위해 등장한 것이 델타 동기화다. 핵심 아이디어는 단순하다:

> "파일 전체가 아닌, 변경된 부분만 전송한다"

### 델타 동기화 작동 원리

#### 1단계: 파일을 블록으로 분할

```kotlin
data class FileBlock(
    val index: Int,
    val data: ByteArray,
    val hash: String,
    val size: Int = data.size
) {
    companion object {
        const val BLOCK_SIZE = 4 * 1024 * 1024 // 4MB 블록
    }
}

class FileBlockManager {
    fun splitFileIntoBlocks(filePath: String): List<FileBlock> {
        val file = File(filePath)
        val blocks = mutableListOf<FileBlock>()
        
        file.inputStream().use { inputStream ->
            var blockIndex = 0
            val buffer = ByteArray(FileBlock.BLOCK_SIZE)
            
            while (true) {
                val bytesRead = inputStream.read(buffer)
                if (bytesRead == -1) break
                
                val blockData = if (bytesRead == FileBlock.BLOCK_SIZE) {
                    buffer.copyOf()
                } else {
                    buffer.copyOf(bytesRead)
                }
                
                val hash = calculateBlockHash(blockData)
                blocks.add(FileBlock(blockIndex++, blockData, hash))
            }
        }
        
        return blocks
    }
    
    private fun calculateBlockHash(data: ByteArray): String {
        val digest = MessageDigest.getInstance("SHA-256")
        val hashBytes = digest.digest(data)
        return hashBytes.joinToString("") { "%02x".format(it) }
    }
}
```

파일을 4MB 단위로 나누고 각 블록마다 SHA-256 해시를 계산한다. 이 해시값이 블록의 지문 역할을 한다.

#### 2단계: 해시 기반 변경 감지

```kotlin
// 변경 감지의 핵심
fun identifyChangedBlocks(
    localBlocks: List<FileBlock>,
    serverHashes: Map<Int, String>
): List<FileBlock> {
    return localBlocks.filter { block ->
        val serverHash = serverHashes[block.index]
        serverHash == null || serverHash != block.hash
    }
}
```

서버에서 각 블록의 해시값만 받아와서 로컬 블록과 비교한다. 해시가 다르면 변경된 블록이다.

#### 3단계: 델타 동기화 실행

```kotlin
class DeltaSyncClient {
    suspend fun syncFile(filePath: String, serverFileInfo: ServerFileInfo): FileDelta {
        // 1. 로컬 파일을 블록으로 분할
        val localBlocks = blockManager.splitFileIntoBlocks(filePath)
        
        // 2. 서버의 블록 해시 정보 가져오기 (가벼운 메타데이터만)
        val serverHashes = getServerBlockHashes(serverFileInfo.fileId)
        
        // 3. 변경된 블록만 식별
        val changedBlocks = identifyChangedBlocks(localBlocks, serverHashes)
        
        // 4. 변경된 블록만 압축해서 전송
        val compressedBlocks = changedBlocks.map { block ->
            block.copy(data = compressor.compress(block.data))
        }
        
        return FileDelta(
            fileId = serverFileInfo.fileId,
            version = serverFileInfo.version + 1,
            changedBlocks = compressedBlocks,
            totalBlocks = localBlocks.size,
            compressionRatio = calculateCompressionRatio(changedBlocks, compressedBlocks)
        )
    }
}
```

### 성능 향상을 위한 추가 기술

#### Rolling Hash와 Content-Defined Chunking

고정 크기 블록의 한계가 있다. 파일 앞부분에 한 글자만 추가되면 모든 블록이 shift되어서 전체 파일을 다시 전송해야 한다. 이를 해결하기 위해 Content-Defined Chunking을 사용한다.

**Rolling Hash:**
슬라이딩 윈도우에서 효율적으로 해시를 계산하는 방법이다.

```kotlin
class RollingHash {
    private val base = 256
    private val mod = 1000000007
    private var currentHash = 0L
    
    fun addByte(byte: Byte) {
        currentHash = (currentHash * base + byte.toUByte().toLong()) % mod
    }
    
    fun removeByte(byte: Byte) {
        currentHash = (currentHash - (byte.toUByte().toLong() * basePow) % mod + mod) % mod
    }
    
    fun hash(): Long = currentHash
}
```

**Content-Defined Chunking:**
내용 기반으로 블록 경계를 정하는 방법이다.

```kotlin
class ContentDefinedChunker {
    private val mask = (1L shl 13) - 1 // 평균 8KB 청크를 위한 마스크
    
    fun createVariableBlocks(data: ByteArray): List<FileBlock> {
        val blocks = mutableListOf<FileBlock>()
        var blockStart = 0
        
        for (i in data.indices) {
            rollingHash.addByte(data[i])
            
            // 특정 패턴이 나타나면 블록 경계로 설정
            if (i >= 64 && (rollingHash.hash() and mask) == 0L) {
                val blockData = data.copyOfRange(blockStart, i + 1)
                val hash = calculateBlockHash(blockData)
                blocks.add(FileBlock(blockIndex++, blockData, hash))
                blockStart = i + 1
            }
        }
        
        return blocks
    }
}
```

이 방법을 사용하면 파일 앞부분에 내용이 추가되어도 대부분의 블록 경계는 그대로 유지된다.

#### Rabin Fingerprinting

Rabin Fingerprinting은 Content-Defined Chunking에 사용되는 특별한 해시 방법이다.

```kotlin
class RabinFingerprint {
    private val polynomial = 0x3DA3358B4DC173L // 기약 다항식
    private var fingerprint = 0L
    
    fun roll(newByte: Byte, oldByte: Byte, windowSize: Int) {
        // 새 바이트 추가
        fingerprint = fingerprint shl 1
        if (fingerprint and (1L shl 63) != 0L) {
            fingerprint = fingerprint xor polynomial
        }
        fingerprint = fingerprint xor newByte.toLong()
    }
    
    fun getValue(): Long = fingerprint
}
```

**Rabin Fingerprinting의 특징:**
- **수학적 기반**: 유한체(finite field) 연산 사용
- **균등 분포**: 해시값이 균등하게 분포됨
- **Rolling 특성**: 윈도우가 이동할 때 효율적으로 계산 가능

### 추가 최적화 방법

#### 1. 적응형 압축

```kotlin
class AdaptiveBlockCompressor {
    fun compress(data: ByteArray, fileType: FileType): ByteArray {
        return when (fileType) {
            FileType.TEXT -> compressWithGzip(data)      // 70-90% 압축률
            FileType.IMAGE -> compressWithWebP(data)     // 무손실 압축
            FileType.VIDEO -> data                       // 이미 압축됨
            FileType.BINARY -> compressWithLZ4(data)     // 빠른 압축
            else -> compressWithGzip(data)
        }
    }
}
```

파일 타입에 따라 다른 압축 알고리즘을 사용한다.

#### 2. 병렬 처리

```kotlin
class ParallelDeltaProcessor {
    suspend fun processFileInParallel(filePath: String): List<FileBlock> {
        val blockCount = calculateBlockCount(filePath)
        val cpuCores = Runtime.getRuntime().availableProcessors()
        val chunkSize = maxOf(1, blockCount / cpuCores)
        
        return (0 until blockCount step chunkSize).map { startBlock ->
            async(Dispatchers.IO) {
                processBlockChunk(file, startBlock, chunkSize)
            }
        }.awaitAll().flatten()
    }
}
```

CPU 코어 수에 맞춰서 블록 처리를 병렬화한다.

---

## Part 2: 강한 일관성 - 모든 사용자가 같은 현실을 보게 하는 방법

### 일관성 문제의 중요성

**문제 상황:**
1. 철수가 "회의록.docx"를 편집 중 (버전 5)
2. 영희가 동시에 같은 파일을 편집 (버전 5 기준)
3. 철수가 먼저 저장 (버전 6 생성)
4. 영희가 나중에 저장 (버전 5 기준으로 편집한 내용)

**결과:** 철수의 변경사항이 사라지거나, 두 버전이 충돌하거나, 사용자마다 다른 버전을 보는 상황이 발생한다.

### 일관성 모델 비교

#### 최종 일관성 (Eventual Consistency)

```kotlin
// NoSQL의 일반적인 접근
fun updateFileWithEventualConsistency(fileId: String, content: String) {
    // 각 노드에 비동기로 업데이트
    node1.updateAsync(fileId, content)
    node2.updateAsync(fileId, content) 
    node3.updateAsync(fileId, content)
    
    // 문제: 일시적으로 노드마다 다른 값을 가질 수 있음
    // 사용자A가 node1에서 조회 → 구버전
    // 사용자B가 node2에서 조회 → 신버전
}
```

#### 강한 일관성 (Strong Consistency)

```kotlin
// 관계형 DB의 ACID 접근
fun updateFileWithStrongConsistency(fileId: String, content: String) {
    transaction {
        // 1. 현재 버전 조회 및 락 설정
        val currentFile = db.selectForUpdate("SELECT * FROM files WHERE id = ?", fileId)
        
        // 2. 버전 검증
        if (currentFile.version != expectedVersion) {
            throw VersionConflictException("File was modified by another user")
        }
        
        // 3. 원자적 업데이트 (모든 작업이 성공하거나 모두 실패)
        db.update("UPDATE files SET content = ?, version = version + 1 WHERE id = ?", 
                  content, fileId)
        
        // 4. 모든 캐시 무효화
        cacheCluster.invalidateAll("file:$fileId")
        
        // 결과: 모든 사용자가 항상 같은 버전을 본다
    }
}
```

### 캐시 무효화의 중요성

분산 시스템에서는 성능을 위해 여러 서버에 캐시를 두는데 이때 캐시 일관성이 중요한 문제가 된다.

**문제 상황:**
```kotlin
class CacheProblem {
    fun problemScenario() {
        // 1. 서버 A에서 파일 읽기
        val fileFromCacheA = cacheA.get("file:123") // "오래된 내용"
        
        // 2. 서버 B에서 파일 업데이트
        database.update("file:123", "새로운 내용")
        cacheB.put("file:123", "새로운 내용")
        
        // 3. 다시 서버 A에서 읽기
        val fileFromCacheA2 = cacheA.get("file:123") // 아직도 "오래된 내용"!!
        
        // 문제: 같은 파일인데 서버마다 다른 내용!
    }
}
```

**해결 방법:**
```kotlin
class ConsistentCacheManager {
    fun updateFileWithCacheInvalidation(fileId: String, newContent: String) {
        database.transaction {
            // 1. DB 업데이트
            updateFileInDatabase(fileId, newContent)
            
            // 2. 로컬 캐시 무효화
            localCache.remove("file:$fileId")
            
            // 3. 다른 모든 서버들에게 캐시 무효화 신호 전송
            publishCacheInvalidation(fileId)
        }
    }
    
    private fun publishCacheInvalidation(fileId: String) {
        // Redis Pub/Sub을 통한 클러스터 전체 캐시 무효화
        redisPublisher.publish("cache:invalidate", JsonObject().apply {
            put("type", "file")
            put("id", fileId)
            put("timestamp", System.currentTimeMillis())
        })
    }
    
    // 다른 노드에서 무효화 신호 수신
    @Subscribe
    fun handleCacheInvalidation(message: CacheInvalidationMessage) {
        when (message.type) {
            "file" -> localCache.remove("file:${message.id}")
            "user" -> localCache.remove("user:${message.id}")
        }
    }
}
```

### Isolation Level 상세

데이터베이스의 격리 수준(Isolation Level)은 동시 트랜잭션들이 서로 어느 정도 격리되는지를 정의한다.

#### 1. READ UNCOMMITTED
- 가장 낮은 격리 수준
- Dirty Read 허용: 다른 트랜잭션이 커밋하지 않은 데이터도 읽을 수 있음

#### 2. READ COMMITTED (기본값)
- Dirty Read 방지
- 하지만 Non-repeatable Read 허용

```kotlin
transaction {
    val version1 = readFile(fileId).version // version = 5
    
    // 이 시점에 다른 트랜잭션이 파일을 수정
    
    val version2 = readFile(fileId).version // version = 6
    // 같은 트랜잭션 내에서 다른 값 읽음
}
```

#### 3. REPEATABLE READ
- Non-repeatable Read 방지
- 하지만 Phantom Read 허용

#### 4. SERIALIZABLE
- 가장 높은 격리 수준
- 모든 동시성 문제 방지
- 하지만 성능 가장 느림

### ACID 속성을 활용한 구현

#### Atomicity (원자성) - 전부 아니면 전무

```kotlin
class FileVersionManager {
    fun createNewVersion(fileId: String, delta: FileDelta): FileUpdateResult {
        return database.transaction {
            try {
                // 1. 새 파일 버전 레코드 생성
                val newVersion = insertFileVersion(fileId, delta.version)
                
                // 2. 블록 정보 업데이트
                delta.changedBlocks.forEach { block ->
                    insertBlockReference(newVersion.id, block)
                }
                
                // 3. 현재 버전 포인터 업데이트
                updateCurrentVersion(fileId, delta.version)
                
                // 4. 사용자 활동 로그
                insertActivityLog(userId, "FILE_UPDATED", fileId)
                
                // 모든 작업이 성공해야만 커밋
                commit()
                FileUpdateResult.Success(newVersion)
                
            } catch (e: Exception) {
                // 하나라도 실패하면 모든 작업 롤백
                rollback()
                FileUpdateResult.Failure(e.message)
            }
        }
    }
}
```

#### Consistency (일관성) - 데이터 무결성 보장

```sql
-- 데이터베이스 스키마 설계
CREATE TABLE files (
    id VARCHAR(36) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    current_version BIGINT NOT NULL DEFAULT 1,
    owner_id VARCHAR(36) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    
    -- 제약 조건으로 일관성 보장
    CONSTRAINT fk_owner FOREIGN KEY (owner_id) REFERENCES users(id),
    CONSTRAINT check_version CHECK (current_version >= 1)
);

CREATE TABLE file_versions (
    id VARCHAR(36) PRIMARY KEY,
    file_id VARCHAR(36) NOT NULL,
    version BIGINT NOT NULL,
    blocks_info JSON NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- 같은 파일의 같은 버전은 중복 불가
    CONSTRAINT uk_file_version UNIQUE (file_id, version),
    CONSTRAINT fk_file FOREIGN KEY (file_id) REFERENCES files(id)
);
```

#### Isolation (격리성) - 동시 접근 제어

```kotlin
class ConcurrentFileEditor {
    fun editFile(fileId: String, changes: List<Change>): EditResult {
        return database.transaction(isolationLevel = SERIALIZABLE) {
            
            // 1. 파일 락 획득 (다른 트랜잭션 대기하게 함)
            val file = db.selectForUpdate(
                "SELECT * FROM files WHERE id = ? FOR UPDATE", 
                fileId
            )
            
            // 2. 낙관적 락 검증
            if (file.version != expectedVersion) {
                throw OptimisticLockException(
                    "File was modified. Expected version: $expectedVersion, " +
                    "Actual version: ${file.version}"
                )
            }
            
            // 3. 변경사항 적용
            applyChanges(file, changes)
            
            // 4. 버전 증가
            updateVersion(fileId, file.version + 1)
            
            EditResult.Success(file.version + 1)
        }
    }
}
```

#### Durability (지속성) - 데이터 영구 보존

```kotlin
class DurableFileStorage {
    fun saveFileChanges(fileId: String, changes: FileChanges) {
        // 1. WAL(Write-Ahead Logging) - 트랜잭션 로그 먼저 기록
        writeAheadLog.append(TransactionLog(
            type = "FILE_UPDATE",
            fileId = fileId,
            changes = changes,
            timestamp = System.currentTimeMillis()
        ))
        
        // 2. 마스터 DB에 변경사항 적용
        masterDB.applyChanges(fileId, changes)
        
        // 3. 슬레이브 DB들에 동기 복제
        slaveDBs.forEach { slave ->
            slave.replicateChanges(fileId, changes)
        }
        
        // 4. 클라우드 스토리지에 백업
        cloudStorage.backup(fileId, changes)
        
        // 5. 로그 커밋 마킹
        writeAheadLog.markCommitted(fileId)
    }
}
```

### 분산 환경에서의 일관성

#### Two-Phase Commit (2PC)

2PC는 분산 트랜잭션에서 원자성을 보장하는 프로토콜이다.

```kotlin
class TwoPhaseCommitCoordinator {
    fun executeDistributedTransaction(operations: List<DistributedOperation>): TransactionResult {
        val transactionId = generateTransactionId()
        
        // Phase 1: Prepare
        val prepareResults = operations.map { operation ->
            operation.node.prepare(transactionId, operation.command)
        }
        
        if (prepareResults.all { it.isSuccess }) {
            // Phase 2a: Commit
            operations.forEach { operation ->
                operation.node.commit(transactionId)
            }
            return TransactionResult.Success
        } else {
            // Phase 2b: Abort
            operations.forEach { operation ->
                operation.node.abort(transactionId)
            }
            return TransactionResult.Failure
        }
    }
}
```

**2PC의 문제점:**
- 코디네이터 장애 시 블로킹
- 네트워크 분할에 취약
- 성능 오버헤드

#### Raft 합의 알고리즘

Raft는 분산 시스템에서 합의를 달성하는 더 실용적인 방법이다.

```kotlin
class RaftNode {
    private var currentTerm = 0L
    private var votedFor: String? = null
    private var state = NodeState.FOLLOWER
    
    fun startElection() {
        state = NodeState.CANDIDATE
        currentTerm++
        votedFor = nodeId
        
        val votes = requestVotesFromOtherNodes()
        
        if (votes > totalNodes / 2) {
            becomeLeader()
        } else {
            state = NodeState.FOLLOWER
        }
    }
}
```

**Raft의 특징:**
- 리더 기반 합의
- 강한 일관성 보장
- 네트워크 분할 시 과반수 노드만 있으면 동작
- 2PC보다 가용성 높음
