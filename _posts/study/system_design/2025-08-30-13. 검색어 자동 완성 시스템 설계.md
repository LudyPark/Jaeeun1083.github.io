---
title: System Design. Part13. 검색어 자동 완성 시스템 설계
author: jaeeun
date: 2025-08-30 00:00:00 +0800
categories: [Study, "SystemDesign"]
tags: ["System Design"]
render_with_liquid: false
---
## 검색어 자동완성 시스템 설계 분석 및 개선안

### 1. 현재 시스템 구조 정리

#### 데이터 수집 파이프라인

```
데이터 분석 로그 → 로그 취합 서버 → 작업 서버 → 트라이 DB → 트라이 캐시
```

**각 컴포넌트 역할:**
- **데이터 분석 로그**: 검색창 입력 질의의 원본 데이터 보관
- **로그 취합 서버**: query, time, frequency 형태로 데이터 정제 및 저장
- **작업 서버**: 트라이 자료구조 생성 및 DB 저장, 주기적 비동기 작업 실행
- **트라이 캐시**: 분산 캐시로 트라이 데이터를 메모리에 유지, 매주 스냅샷 갱신
- **트라이 데이터베이스**: 지속성 저장소 (문서 저장소 + 키값 저장소)

#### 질의 서비스 플로우
```
검색 질의 → 로드밸런서 → API 서버 → 트라이 캐시 → (캐시 미스시) DB
```

### 2. 질문과 답변

#### Q1. 다국어 지원 확장 방법은?

**답변:**
- **유니코드 저장**: 트라이 노드에 UTF-8/UTF-16 인코딩으로 다국어 문자 저장
- **언어별 인덱싱**: 각 언어의 문자 체계에 맞는 트라이 구조 설계
- **토크나이징**: 중국어/일본어 등은 형태소 분석기를 통한 단어 단위 처리
- **정규화**: 대소문자, 발음 기호 등의 정규화 처리

#### Q2. 국가별 인기 검색어 차이 해결 방법은?

**답변:**
- **지역별 트라이**: 국가/언어별로 독립적인 트라이 구조 유지
- **CDN 활용**: 지역별 트라이를 해당 지역 CDN에 캐싱하여 응답 속도 최적화
- **지역 감지**: 사용자 IP/언어 설정 기반으로 적절한 트라이 선택

#### Q3. 실시간 검색어 추이 반영 방법은?

**현재 설계의 한계:**
- 매주 한 번의 갱신으로는 실시간 트렌드 반영 불가
- 트라이 재구성에 많은 시간 소요

**개선 방안:**
- **핫 데이터 레이어**: 최근 N시간의 급상승 검색어를 별도 레이어에서 처리
- **하이브리드 모델**: 정적 트라이 + 동적 실시간 검색어 조합
- **가중치 조정**: 시간 기반 decay 함수를 적용한 검색어 점수 계산

### 3. 시스템 개선안

#### 3.1 실시간 처리를 위한 Lambda Architecture

```
배치 레이어 (기존):  데이터 로그 → 작업 서버 → 트라이 DB (주단위)
속도 레이어 (신규):  실시간 로그 → Kafka → Spark Streaming → 실시간 캐시 (분단위)
서비스 레이어:       API 서버 → (실시간 캐시 + 트라이 캐시) → 결과 병합
```

```python
# 배치 레이어 (기존): 정확하지만 느림
def batch_layer():
    weekly_trie = process_all_historical_data()  # 정확함
    return weekly_trie

# 스피드 레이어 (신규): 빠르지만 근사치
def speed_layer():
    recent_trends = process_last_hour_data()  # 빠름
    return recent_trends

# 서빙 레이어: 둘을 합쳐서 응답
def serve_request(prefix):
    batch_result = batch_layer.search(prefix)      # 기본 결과
    speed_result = speed_layer.search(prefix)      # 실시간 트렌드
    
    # 합치기: 실시간 트렌드에 가산점
    final_result = merge_with_boost(batch_result, speed_result)
    return final_result
```

#### 3.2 향상된 캐싱 전략

**계층적 캐시 구조:**
- **L1 캐시**: API 서버 로컬 캐시 (가장 빈번한 검색어)
- **L2 캐시**: Redis 클러스터 (지역별 인기 검색어)
- **L3 캐시**: 트라이 DB (전체 검색어)

```python
# L1 캐시 (API 서버 메모리): 초고속, 용량 작음
l1_cache = {}  # "파이썬", "자바" 같은 초빈번 검색어

# L2 캐시 (Redis): 빠름, 용량 중간  
redis_cache = Redis()  # "파이", "자바스크립트" 등 빈번한 prefix

# L3 캐시 (DB): 느림, 용량 큼
database = Database()  # 모든 검색어

def search_with_hierarchy(prefix):
    # 1차: 서버 메모리에서 찾기
    if prefix in l1_cache:
        return l1_cache[prefix]
    
    # 2차: Redis에서 찾기    
    result = redis_cache.get(prefix)
    if result:
        l1_cache[prefix] = result  # 위로 올리기
        return result
    
    # 3차: DB에서 찾기
    result = database.search(prefix)
    redis_cache.set(prefix, result)
    l1_cache[prefix] = result
    return result
```

#### 3.3 개선된 샤딩 전략

**Consistent Hashing + 데이터 분포 분석:**
```python
# 기존 단순 샤딩 (알파벳 기준)
def simple_shard(query):
    first_letter = query[0]
    if 'a' <= first_letter <= 'm':
        return "server1"
    else:
        return "server2"

# 샤딩 (일관성 해싱 + 데이터 분석)
# 과거 데이터 분석해서 균등하게 분배
def smart_shard(query):
    # 실제 검색량 기반으로 가중치 계산
    weight = calculate_weight_from_historical_data(query)
    hash_value = hash(query) * weight
    return hash_value % num_servers

# 결과: 각 서버가 비슷한 양의 데이터 처리
```

#### 3.4 모니터링 및 관찰성

**핵심 메트릭:**
- 검색 응답 시간 (P50, P95, P99)
- 캐시 적중률
- 트라이 갱신 소요 시간
- 샤드별 부하 분산 상태

**알림 시스템:**
- 응답 시간 임계값 초과
- 캐시 적중률 급격한 하락
- 특정 샤드 과부하

#### 3.5 확장성 고려사항

**수평적 확장:**
- API 서버: 로드밸런서를 통한 무상태 확장
- 캐시 레이어: Redis Cluster 샤딩
- 데이터베이스: 트라이별 파티셔닝

**수직적 최적화:**
- 메모리 최적화된 트라이 구조
- SSD 기반 스토리지 활용
- CPU 캐시 친화적인 데이터 레이아웃
